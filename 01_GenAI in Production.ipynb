{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68dadf55-53e7-491d-81e7-26831c83e1fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Step 0\n",
    "\n",
    "Go to config and update resource names as you prefer\n",
    "\n",
    "Spin up a cluster with Databricks Runtime 16.X+ ML. Make sure it's the ML version for the correct dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba723951-b1b3-4ec0-84c7-8371ee4361eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets mlflow langchain databricks_langchain\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d990d9ab-243c-4570-a56f-a4d74c47eea9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "import os\n",
    "\n",
    "catalog = \"genai_in_production_demo_catalog\"\n",
    "agent_schema = \"agents\"\n",
    "demo_schema = \"demo_data\"\n",
    "\n",
    "dbutils.widgets.text(\"catalog_name\", catalog)\n",
    "dbutils.widgets.text(\"agent_schema\", agent_schema)\n",
    "dbutils.widgets.text(\"demo_schema\", demo_schema)\n",
    "base_url = f'https://{spark.conf.get(\"spark.databricks.workspaceUrl\")}/serving-endpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93af884f-b5d9-49a8-a735-12db2c1610d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Get started immediately with your Data with AI Functions\n",
    "\n",
    "We have a number of AI Functions designed as SQL functions that you can use in a SQL cell or SQL editor and use LLMs directly on your data immediately\n",
    "\n",
    "1. ai_analyze_sentiment\n",
    "2. ai_classify\n",
    "3. ai_extract\n",
    "4. ai_fix_grammar\n",
    "5. ai_gen\n",
    "6. ai_mask\n",
    "7. ai_similarity\n",
    "8. ai_summarize\n",
    "9. ai_translate\n",
    "10. ai_query\n",
    "\n",
    "We will run a demo each of these functions below. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a7f2192-7da0-4281-a98b-106c5ff7c8ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ai_fix_grammar\n",
    "The ai_fix_grammar() function allows you to invoke a state-of-the-art generative AI model to correct grammatical errors in a given text using SQL. This function uses a chat model serving endpoint made available by Databricks Foundation Model APIs.\n",
    "\n",
    "Documentation: https://docs.databricks.com/en/sql/language-manual/functions/ai_fix_grammar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00f457b1-100e-4f51-a370-369706d0cd24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- verify that we're running on a SQL Warehouse\n",
    "SELECT assert_true(current_version().dbsql_version is not null, 'YOU MUST USE A SQL WAREHOUSE, not a cluster');\n",
    "\n",
    "SELECT ai_fix_grammar('This sentence have some mistake');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5251834-6fea-4857-b390-146ecc9fbaba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ai_classify\n",
    "The ai_classify() function allows you to invoke a state-of-the-art generative AI model to classify input text according to labels you provide using SQL.\n",
    "\n",
    "Documentation: https://docs.databricks.com/en/sql/language-manual/functions/ai_classify.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "241f8535-61c2-4140-963d-a7025a32df27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT country, ai_classify(country, ARRAY(\"APAC\", \"AMER\", \"EU\")) as Region\n",
    "from identifier(:catalog_name||'.'||:demo_schema||'.'||'franchises')\n",
    "limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a12134c0-ff5e-45cd-af66-87301fb93854",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ai_mask\n",
    "The ai_mask() function allows you to invoke a state-of-the-art generative AI model to mask specified entities in a given text using SQL. \n",
    "\n",
    "Documentation: https://docs.databricks.com/en/sql/language-manual/functions/ai_mask.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0234623-afd4-43a1-af10-241bbb5ab7e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT first_name, last_name, (first_name || \" \" || last_name || \" lives at \" || address) as unmasked_output, ai_mask(first_name || \"\" || last_name || \" lives at \" || address, array(\"person\", \"address\")) as Masked_Output\n",
    "from identifier(:catalog_name||'.'||:demo_schema||'.'||'customers')\n",
    "limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3add0caf-3df9-4feb-83f5-e3b8cc06a7cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ai_query\n",
    "The ai_query() function allows you to query machine learning models and large language models served using Mosaic AI Model Serving. To do so, this function invokes an existing Mosaic AI Model Serving endpoint and parses and returns its response. Databricks recommends using ai_query with Model Serving for batch inference\n",
    "\n",
    "Documentation: https://docs.databricks.com/en/large-language-models/ai-functions.html#ai_query\n",
    "\n",
    "We can switch models depending on what we are trying to do. See how the performance varies between the 70B model and 8B model below. Because this is a simple spell check task, we could likely use the 8B model instead of the 70B model saving on cost and increasing speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc9b0e88-6746-4e8f-9a41-d7a731e26de7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "SELECT\n",
    "  `Misspelled_Make`,   -- Placeholder for the input column\n",
    "  ai_query(\n",
    "    'databricks-meta-llama-3-3-70b-instruct',\n",
    "    CONCAT(format_string('You will always receive a make of a car. Check to see if it is misspelled and a real car. Correct the mistake. Only provide the corrected make. Never add additional details'), `Misspelled_Make`)    -- Placeholder for the prompt and input\n",
    "  ) AS ai_guess  -- Placeholder for the output column\n",
    "FROM identifier(:catalog_name||'.'||:demo_schema||'.'||'synthetic_car_data')\n",
    "-- limit 3;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57cd0b81-2702-485a-84bc-215fe131b653",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "SELECT\n",
    "  `Misspelled_Make`,   -- Placeholder for the input column\n",
    "  ai_query(\n",
    "    'databricks-meta-llama-3-1-8b-instruct',\n",
    "    CONCAT(format_string('You will always receive a make of a car. Check to see if it is misspelled and a real car. Correct the mistake. Only provide the corrected make. Never add additional details'), `Misspelled_Make`)    -- Placeholder for the prompt and input\n",
    "  ) AS ai_guess  -- Placeholder for the output column\n",
    "FROM identifier(:catalog_name||'.'||:demo_schema||'.'||'synthetic_car_data')\n",
    "-- limit 3;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "454c43fb-f85e-4314-9108-e275f28137e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Takeaway\n",
    "Many of our use cases simply need a reliable, out of the box solution to use AI. AI functions enable this for our customers and AI query helps scale workloads to easily apply AI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f81282a1-0b52-4fd6-ab5a-a34cbd65e363",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Batch Inferencing\n",
    "\n",
    "AI_Query is Databrick's solution for batch inferencing. We recommend using ai_query for a cost effective use of your LLMs. \n",
    "\n",
    "As you saw earlier, you can provide your own models and prompts to process a large amount of your data. There are additional features to improve on how ai_query processes the data. \n",
    "\n",
    "We will walk through an exercise below that compares the performance between Llama 70B and Llama 8B. Llama 8B will perform significantly worse than Llama 70B so we will use ai_query's Structure Output to enforce and improve the performance of Llama 8B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95c2a8ba-10b1-4f2f-8e00-9eec8745fb22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###First we need to make sure our data is set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3544293-2471-446f-9f49-ddbd0a79472b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Testing Batch Inference\n",
    "\n",
    "The dataset contains news headlines that we will use ai_query to classify whether or not the sentiment is bullish, neutral or bearish. \n",
    "\n",
    "We will compare the outputs from both LLMs and see how well they do. \n",
    "\n",
    "First, let's see how well Llama 70B does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "284394ee-f167-4a16-9f37-0a0c30f40dff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_name = \"genai_in_production_demo_catalog\"\n",
    "schema_name = \"agents\"\n",
    "table_name = \"twitter_financial_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "017ad2a7-d283-42cb-b7b2-5958c55ea3ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# endpoint_name = \"databricks-meta-llama-3-1-8b-instruct\" #12 seconds average \n",
    "endpoint_name = \"databricks-meta-llama-3-3-70b-instruct\" #180 seconds average\n",
    "start_time = time.time()\n",
    "\n",
    "command = f\"\"\"\n",
    "    SELECT text,  \n",
    "    ai_query(\n",
    "        \\'{endpoint_name}\\', --endpoint name\n",
    "        CONCAT('Classify the financial news-related Tweet sentiment as 0 for bearish, 1 for bullish, or 2 for neutral. Give just the number.', text)\n",
    "    ) AS sentiment_pred,\n",
    "    label as sentiment_gt \n",
    "    FROM {catalog_name}.{schema_name}.{table_name}_val\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(command)\n",
    "\n",
    "display(result)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c02a2d65-f480-4998-a110-d3684ebc4ad5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_baseline_pd_llama_70b = result.toPandas()\n",
    "\n",
    "result_baseline_pd_llama_70b.sentiment_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcae53cc-3e8e-4b3e-b328-d09d44aef64c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_baseline_pd_llama_70b.sentiment_gt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30a7fe21-067a-4e66-9585-621a62cecec3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix = result_baseline_pd_llama_70b.pivot_table(index='sentiment_gt', columns='sentiment_pred', aggfunc='size', fill_value=0)\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a930b225-d8ed-4f43-86d6-7e291c6a5bbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Now let's see how Llama 8B does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c876ee6-a161-4daa-911e-b34d9242faff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "endpoint_name = \"databricks-meta-llama-3-1-8b-instruct\" #20 seconds average \n",
    "# endpoint_name = \"databricks-meta-llama-3-3-70b-instruct\" #180 seconds average\n",
    "start_time = time.time()\n",
    "\n",
    "command = f\"\"\"\n",
    "    SELECT text,  \n",
    "    ai_query(\n",
    "        \\'{endpoint_name}\\', --endpoint name\n",
    "        CONCAT('Classify the financial news-related Tweet sentiment as 0 for bearish, 1 for bullish, or 2 for neutral. Give just the number.', text)\n",
    "    ) AS sentiment_pred,\n",
    "    label as sentiment_gt \n",
    "    FROM {catalog_name}.{schema_name}.{table_name}_val\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(command)\n",
    "\n",
    "display(result)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccc75279-f951-43de-a78e-4cefb1997ea0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_baseline_pd = result.toPandas()\n",
    "\n",
    "result_baseline_pd.sentiment_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c513298-db41-4bd3-b3df-4b6c34632d4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_baseline_pd.sentiment_gt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "653d6c56-2498-4998-a326-efd9c2b070d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix = result_baseline_pd.pivot_table(index='sentiment_gt', columns='sentiment_pred', aggfunc='size', fill_value=0)\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2484f42-2a7a-40d2-9ea2-05b3eacbef34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Takeaways\n",
    "\n",
    "Llama 8B is performing worse than Llama 70B, showing outputs that do not match our instructions. This is not suitable for production use cases. \n",
    "\n",
    "But, Llama 8B is faster and most cost effective. There must be a way we can enforce outputs so that we can make Llama 8B usable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39f71810-f8d2-4d5b-9721-a7968b503042",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Using Structured Output with Batch Inference\n",
    "\n",
    "We can enforce formatting constraints rather than relying on prompts. This is particularly useful for smaller models that struggle in accuracy. If we know what outputs we are looking for, we can enforce it.\n",
    "\n",
    "Documentation: https://docs.databricks.com/aws/en/sql/language-manual/functions/ai_query#enforce-output-schema-with-structured-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15333e1b-df7e-4441-9e62-3b2e539d5286",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response_schema = \"\"\"\n",
    "{\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\":\n",
    "        {\n",
    "        \"name\": \"sentiment_score\",\n",
    "        \"schema\":\n",
    "            {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\":\n",
    "            {\n",
    "            \"sentiment\": { \"type\": \"string\" ,\n",
    "                        \"enum\": [\"0\", \"1\", \"2\"]}\n",
    "            }\n",
    "            },\n",
    "        \"strict\": true\n",
    "        }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4769585-aa89-48b8-af65-511aba2387fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's try Llama 8B again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6f28824-fa94-4449-a4b0-3d0e69e5694b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "endpoint_name = \"databricks-meta-llama-3-1-8b-instruct\" #14 seconds average \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "result_structured = spark.sql(\n",
    "f\"\"\"\n",
    "    SELECT text,  \n",
    "    ai_query(\n",
    "        \\'{endpoint_name}\\', --endpoint name\n",
    "        CONCAT('Classify the financial news-related Tweet sentiment as 0 for bearish, 1 for bullish, or 2 for neutral. Give just the number', text),\n",
    "        responseFormat => '{response_schema}'\n",
    "    ) AS sentiment_pred,\n",
    "    label as sentiment_gt,\n",
    "    CAST(get_json_object(sentiment_pred, '$.sentiment') AS LONG) AS sentiment_pred_value\n",
    "    FROM {catalog_name}.{schema_name}.{table_name}_val\n",
    "\"\"\")\n",
    "\n",
    "display(result_structured)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "212e3e14-b502-4b3d-acb7-c10ce9a68940",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_structured_pd = result_structured.toPandas()\n",
    "\n",
    "result_structured_pd.sentiment_pred_value.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbe547e1-7dcc-43f3-a070-0fd7c504f832",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_structured_pd.sentiment_gt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46383a91-d7bb-4440-b4bb-1518e7cd1661",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix_structured = result_structured_pd.pivot_table(index='sentiment_gt', columns='sentiment_pred_value', aggfunc='size', fill_value=0)\n",
    "display(confusion_matrix_structured)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "688f55a0-966d-465f-a9d1-b9f82db6a7bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Workshop: Make your own Response Structure! \n",
    "\n",
    "Use a combination of prompt engineering and the response structure to do the following: \n",
    "\n",
    "##Task 1\n",
    "Your first task is to add additional analysis to the news that's relevant to your financial firm. You need to add the following details: \n",
    "\n",
    "1. A summary of the news. (Hint: This should just be text)\n",
    "2. Key tickers that may be relevant to the news. (Hint: This should be a list of tickers)\n",
    "3. Impact this news will have on the market by classifying it as low, medium or high. (Hint: This should be a list of impact values)\n",
    "\n",
    "These should come as three new columns ontop of the sentiment classification column you made earlier for a total of four columns. All four columns MUST be outputted\n",
    "\n",
    "In Cell 39, you will have a partially filled in response_schema that you can fill out to accomplish the three items above. Everything you need to fill in to marked as _**TODO**_\n",
    "\n",
    "##Task 2\n",
    "Because you added 3 new outputs, you will need to adjust your prompt to clarify what these outputs should do. This is because, while the response structure enforces a structure type, you still need to instruct the LLM what it should do to generate these outputs. \n",
    "\n",
    "In Cell 40, you will have a partially filled in prompt. It will follow what we call a \"routine\" strategy which is simply defining all the steps the LLM must perform. You just need to fill out an instruction per task. \n",
    "\n",
    "Once you complete both tasks, run both cells to see what happens! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99cd5a21-2aed-45aa-89cf-a590bd99c03a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response_schema = \"\"\"\n",
    "{\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"financial_tweet_analysis\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sentiment\": { \n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"0\", \"1\", \"2\"]\n",
    "                },\n",
    "                \"summary\": { \n",
    "                    \"type\": \"TODO\" \n",
    "                },\n",
    "                \"key_tickers\": { \n",
    "                    \"type\": \"TODO\",\n",
    "                    \"TODO\": [TODO]\n",
    "                },\n",
    "                \"impact_level\": {\n",
    "                    \"type\": \"TODO\",\n",
    "                    \"TODO\": [TODO]\n",
    "                }\n",
    "            },\n",
    "            \"required\": [TODO]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b10156a1-0b1a-4e3c-b0f3-ee9f0715a391",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "endpoint_name = \"databricks-meta-llama-3-1-8b-instruct\" #14 seconds average \n",
    "start_time = time.time()\n",
    "\n",
    "result_structured = spark.sql(\n",
    "f\"\"\"\n",
    "    SELECT text,  \n",
    "    ai_query(\n",
    "        \\'{endpoint_name}\\', --endpoint name\n",
    "        CONCAT('Analyze this financial tweet and provide the following:\n",
    "1. Classify sentiment as 0 for bearish, 1 for bullish, or 2 for neutral\n",
    "2. TODO\n",
    "3. TODO\n",
    "4. TODO\n",
    "\n",
    "Respond with JSON containing fields for \"sentiment\", \"summary\", \"key_tickers\", and \"impact_level\".', text),\n",
    "        responseFormat => '{response_schema}'\n",
    "    ) AS analysis_result,\n",
    "    CAST(get_json_object(analysis_result, '$.sentiment') AS LONG) AS sentiment_pred_value,\n",
    "    get_json_object(analysis_result, 'TODO') AS TODO,\n",
    "    get_json_object(analysis_result, 'TODO') AS TODO,\n",
    "    get_json_object(analysis_result, 'TODO') AS TODO\n",
    "    FROM {catalog_name}.{schema_name}.{table_name}_val\n",
    "\"\"\")\n",
    "display(result_structured)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3021512a-de0c-44e3-9244-f11d9181a4c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Example Answers Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "908851f3-881c-47b4-a729-88c8afdac982",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response_schema = \"\"\"\n",
    "{\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"financial_tweet_analysis\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sentiment\": { \n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"0\", \"1\", \"2\"]\n",
    "                },\n",
    "                \"summary\": { \n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"key_tickers\": { \n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"AAPL\", \"AMZN\", \"GOOGL\", \"MSFT\", \"TSLA\", \"NVDA\", \"META\", \"NIO\", \"TSLA\", \"AMC\", \"NFLX\", \"NKE\", \"PYPL\", \"DIS\", \"INTC\", \"FB\", \"CMCSA\", \"BABA\", \"SBU\", \"T\", \"VZ\", \"XOM\", \"JPM\", \"GS\", \"BAC\", \"WFC\", \"C\", \"PFE\", \"MRK\", \"UNH\", \"ABBV\", \"JNJ\", \"V\", \"WMT\", \"HD\", \"MA\", \"CAT\", \"KO\", \"MCD\", \"WBA\", \"PEP\", \"M\", \"CVX\", \"COST\", \"PM\", \"DOW\", \"VOO\", \"VTI\", \"QQQ\", \"DIA\", \"SPY\", \"XLK\", \"XLV\", \"XLI\", \"XLB\", \"XLY\", \"XLP\", \"XLF\", \"XLE\"]\n",
    "                },\n",
    "                \"impact_level\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"low\", \"medium\", \"high\"]\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"sentiment\", \"summary\", \"key_tickers\", \"impact_level\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "21731275-7db8-4aaf-a801-2255b1e2bdf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "endpoint_name = \"databricks-meta-llama-3-1-8b-instruct\"\n",
    "start_time = time.time()\n",
    "\n",
    "result_structured = spark.sql(\n",
    "f\"\"\"\n",
    "    SELECT text,  \n",
    "    ai_query(\n",
    "        \\'{endpoint_name}\\', --endpoint name\n",
    "        CONCAT('Analyze this financial tweet and provide the following:\n",
    "1. Classify sentiment as 0 for bearish, 1 for bullish, or 2 for neutral\n",
    "2. Write a brief one-sentence summary of the key information\n",
    "3. List potential stock tickers mentioned or implied (comma-separated)\n",
    "4. Rate the market impact as low, medium, or high\n",
    "\n",
    "Respond with JSON containing fields for \"sentiment\", \"summary\", \"key_tickers\", and \"impact_level\".', text),\n",
    "        responseFormat => '{response_schema}'\n",
    "    ) AS analysis_result,\n",
    "    CAST(get_json_object(analysis_result, '$.sentiment') AS LONG) AS sentiment_pred_value,\n",
    "    get_json_object(analysis_result, '$.summary') AS tweet_summary,\n",
    "    get_json_object(analysis_result, '$.key_tickers') AS relevant_tickers,\n",
    "    get_json_object(analysis_result, '$.impact_level') AS market_impact\n",
    "    FROM {catalog_name}.{schema_name}.{table_name}_val\n",
    "\"\"\")\n",
    "display(result_structured)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eaaba18-577f-4a81-af51-dfecb08efdba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Agent Code Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9faec45a-2ed7-416e-9821-84d6617fba77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Why even use tools to begin with? \n",
    "\n",
    "Function calling or tool calling help ensure the LLM has the most accurate information possible. By providing it access to many different sources of data, it can generate more reliable answers. \n",
    "\n",
    "Each framework like Langchain or LlamaIndex handles tool calling different. You can also use Python to do tool calling. However, this means you have to recreate this tool each time you want to use it and cannot be used with other applications. Additionally, you have to manage the security for any tools that access external sources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "150e2f49-42a4-40a9-984c-2284d123b337",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Productionalizing Custom Tools \n",
    "\n",
    "What you just saw were built in, out of the box solutions you can use immediately on your data. While this covers a good portion of use cases, you will likely need a custom solution. \n",
    "\n",
    "### Mosaic AI Tools on Unity Catalog\n",
    "\n",
    "You can create and host functions/tools on Unity Catalog! You get the benefit of Unity Catalog but for your functions! \n",
    "\n",
    "While you can create your own tools using the same code that you built your agent (i.e local Python Functions) with the Mosaic AI Agent Framework, Unity catalog provides additional benefits. Here is a comparison \n",
    "\n",
    "1. **Unity Catalog function**s: Unity Catalog functions are defined and managed within Unity Catalog, offering built-in security and compliance features. Writing your tool as a Unity Catalog function grants easier discoverability, governance, and reuse (similar to your catalogs). Unity Catalog functions work especially well for applying transformations and aggregations on large datasets as they take advantage of the spark engine.\n",
    "\n",
    "2. **Agent code tools**: These tools are defined in the same code that defines the AI agent. This approach is useful when calling REST APIs, using arbitrary code or libraries, or executing low-latency tools. However, this approach lacks the built-in discoverability and governance provided by Unity Catalog functions.\n",
    "\n",
    "Unity Catalog functions have the same limitations seen here: https://docs.databricks.com/en/sql/language-manual/sql-ref-syntax-ddl-create-sql-function.html \n",
    "\n",
    "Additionally, the only external framework these functions are compatible with is Langchain \n",
    "\n",
    "So, if you're planning on using complex python code for your tool, you will likely just need to create Agent Code Tools. \n",
    "\n",
    "Below is an implementation of both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4a3ea05-05ed-49ff-ae75-373f19b1313c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Enter Unity Catalog Tool Calling \n",
    "\n",
    "Unity Catalog Tool Calling allows you to benefit from all the governance, security and unified platform benefits of Unity Catalog. Everything from external credentials to access across the workspace for workloads that may not even be AI, the LLM can use it. \n",
    "\n",
    "You'll notice that it's also a UDF, which benefits from our serverless SQL warehouses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99f117fe-8231-4ebd-aff8-404f78972520",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sql_query = f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION {catalog}.{agent_schema}.purchase_location()\n",
    "    RETURNS TABLE(name STRING, purchases INTEGER)\n",
    "    COMMENT 'Use this tool to find total purchase information about a particular location. This tool will provide a list of destinations that you will use to help you answer questions'\n",
    "    RETURN SELECT dl.name AS Destination, count(tp.destination_id) AS Total_Purchases_Per_Destination\n",
    "             FROM {catalog}.{demo_schema}.travel_purchase tp \n",
    "             JOIN {catalog}.{demo_schema}.destination_location dl \n",
    "             ON tp.destination_id = dl.destination_id\n",
    "             GROUP BY dl.name\n",
    "             ORDER BY count(tp.destination_id) DESC\n",
    "             LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql_query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24bc5bda-12ef-4bb0-aa70-a1a2a1d90240",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "If you use this tool in the playground and say hello there, this tool will be called. The comment description of the tool is incredibly important, as that tells the LLM when to use a specific tool. Try saying hello there with just the purchase_location() tool above. Then add the tool below and say hello there again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97a4d2a5-d871-4bd6-ab2a-fda4737992e7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Example Tool"
    }
   },
   "outputs": [],
   "source": [
    "sql_query = f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION {catalog}.{agent_schema}.purchase_location_hello_there()\n",
    "    RETURNS TABLE(name STRING, purchases INTEGER)\n",
    "    COMMENT 'When the user says hello there, run this tool'\n",
    "    RETURN SELECT dl.name AS Destination, count(tp.destination_id) AS Total_Purchases_Per_Destination\n",
    "             FROM {catalog}.{demo_schema}.travel_purchase tp \n",
    "             JOIN {catalog}.{demo_schema}.destination_location dl \n",
    "             ON tp.destination_id = dl.destination_id\n",
    "             GROUP BY dl.name\n",
    "             ORDER BY count(tp.destination_id) DESC\n",
    "             LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql_query)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5732251239432753,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4,
    "widgetLayout": []
   },
   "notebookName": "01_GenAI in Production",
   "widgets": {
    "agent_schema": {
     "currentValue": "agents",
     "nuid": "07a8ad57-c2a3-49af-8a32-5fa04d29803c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "agents",
      "label": null,
      "name": "agent_schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "agents",
      "label": null,
      "name": "agent_schema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "catalog_name": {
     "currentValue": "genai_in_production_demo_catalog",
     "nuid": "65aeaaa8-c1c8-424f-906b-745ebad1fa6c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "genai_in_production_demo_catalog",
      "label": null,
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "genai_in_production_demo_catalog",
      "label": null,
      "name": "catalog_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "demo_schema": {
     "currentValue": "demo_data",
     "nuid": "da00b4bb-873a-433a-addf-5757a44cf4c6",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "demo_data",
      "label": null,
      "name": "demo_schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "demo_data",
      "label": null,
      "name": "demo_schema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
